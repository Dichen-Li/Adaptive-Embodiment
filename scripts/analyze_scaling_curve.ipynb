{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# Replace with the actual paths to your JSON files\n",
    "json_paths = [os.path.join(os.path.dirname(os.getcwd()), 'log_dir/scaling_factor_0.1_v3_modelscale3_attempt2_bs256_acc1_clipv5.0_configv2_scratch_e10/eval_student_model_urma.json'),\n",
    "              os.path.join(os.path.dirname(os.getcwd()), 'log_dir/scaling_factor_0.3_v3_modelscale3_attempt2_bs256_acc1_clipv5.0_configv2_scratch_e10_liu/eval_student_model_urma.json'),\n",
    "              os.path.join(os.path.dirname(os.getcwd()), 'log_dir/scaling_factor_0.5_v3_modelscale3_attempt2_bs256_acc1_clipv5.0_configv2_scratch_e10/eval_student_model_urma.json'),\n",
    "                os.path.join(os.path.dirname(os.getcwd()), 'log_dir/scaling_factor_1.0_v3_modelscale3_attempt2_bs256_acc1_clipv5.0_configv2_scratch_resumee3_3_liu/eval_student_model_urma.json'),\n",
    "              ]\n",
    "\n",
    "# Function to read JSON files and load dictionaries\n",
    "def load_dicts_from_json(paths):\n",
    "    data_dicts = []\n",
    "    for path in paths:\n",
    "        with open(path, \"r\") as f:\n",
    "            data_dicts.append(json.load(f))\n",
    "    return data_dicts\n",
    "\n",
    "# Function to calculate means and standard deviations\n",
    "def calculate_stats(data_dicts):\n",
    "    means = []\n",
    "    stds = []\n",
    "    for data in data_dicts:\n",
    "        values = [v[\"average_return\"] for v in data.values()]\n",
    "        means.append(np.mean(values))\n",
    "        stds.append(np.std(values))\n",
    "    return means, stds\n",
    "\n",
    "# Load data from JSON files\n",
    "data_dicts = load_dicts_from_json(json_paths)"
   ],
   "id": "bbdc7af3b476128"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "\n",
    "# Function to check if a value is NaN\n",
    "def is_nan(value):\n",
    "    return isinstance(value, float) and math.isnan(value)\n",
    "\n",
    "def remove_nans(data_dict):\n",
    "    # Iterate through the list of dictionaries\n",
    "    for dict_index, data in enumerate(data_dict):\n",
    "        keys_to_remove = []  # Collect keys to remove in this dict\n",
    "        for key, sub_dict in data.items():\n",
    "            if 'average_return' in sub_dict and is_nan(sub_dict['average_return']):\n",
    "                # Log info message\n",
    "                print(f\"[INFO] NaN value found in entry '{key}' at index {dict_index}\")\n",
    "                # Add the key to the removal list\n",
    "                keys_to_remove.append(key)\n",
    "        # Remove the keys with NaN values\n",
    "        for key in keys_to_remove:\n",
    "            del data[key]\n",
    "    return data_dict\n",
    "\n",
    "data_dicts = remove_nans(data_dicts)"
   ],
   "id": "7eec99506b45b8a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "labels = ['10%', '30%', '50%', '100%']\n",
    "\n",
    "for i, data_dict in enumerate(data_dicts):\n",
    "    # Extract Gendogs and their average returns\n",
    "    gendogs = list(data_dict.keys())\n",
    "    rewards = [data_dict[gendog]['average_return'] for gendog in gendogs]\n",
    "\n",
    "    # X positions for the bars\n",
    "    x = np.arange(len(gendogs))  # The label locations\n",
    "    width = 0.35  # Width of the bars\n",
    "\n",
    "    plt.bar(x + i*width/len(data_dicts), rewards, width, label=labels[i], alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Comparison of Average Returns for Each Gendog\", fontsize=16)\n",
    "plt.xlabel(\"Gendog\", fontsize=14)\n",
    "plt.ylabel(\"Average Return\", fontsize=14)\n",
    "plt.xticks(x, gendogs, fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "59b2273fe119e371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms for all dictionaries in separate subplots\n",
    "def plot_histograms_separately(data_dicts):\n",
    "    num_dicts = len(data_dicts)\n",
    "    cols = 2  # Number of columns for subplots\n",
    "    rows = (num_dicts + 1) // cols  # Calculate the number of rows needed\n",
    "\n",
    "    plt.figure(figsize=(12, rows * 4))\n",
    "\n",
    "    for i, data_dict in enumerate(data_dicts):\n",
    "        values = [v[\"average_return\"] for v in data_dict.values()]\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.hist(values, bins=20, color='purple', alpha=0.7)\n",
    "        plt.xlabel(\"Average Return\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(f\"Histogram for File {i+1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if data_dicts:\n",
    "    plot_histograms_separately(data_dicts)\n"
   ],
   "id": "f0d520a8958c0f8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize expert performance\n",
   "id": "964ac6f26826e98c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_rewards_as_dict(base_path, tasks):\n",
    "    \"\"\"\n",
    "    Extract the most recent 'average_return' for each task and return as a single dictionary.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for task_prefix in tasks:\n",
    "        # Find all folders matching the task prefix\n",
    "        matching_folders = [\n",
    "            f for f in os.listdir(base_path) if f.startswith(task_prefix) and os.path.isdir(os.path.join(base_path, f))\n",
    "        ]\n",
    "\n",
    "        if not matching_folders:\n",
    "            print(f\"No matching folders found for task prefix '{task_prefix}'\")\n",
    "            continue\n",
    "\n",
    "        # Find the most recent subfolder\n",
    "        most_recent = None\n",
    "        for folder in matching_folders:\n",
    "            task_path = os.path.join(base_path, folder)\n",
    "            subfolders = [\n",
    "                d for d in os.listdir(task_path)\n",
    "                if os.path.isdir(os.path.join(task_path, d)) and d.replace(\"_\", \"-\").replace(\"-\", \"\").isdigit()\n",
    "            ]\n",
    "\n",
    "            if not subfolders:\n",
    "                continue\n",
    "\n",
    "            subfolders.sort(key=lambda d: datetime.strptime(d, \"%Y-%m-%d_%H-%M-%S\"), reverse=True)\n",
    "            recent_subfolder = subfolders[0]\n",
    "            recent_path = os.path.join(task_path, recent_subfolder, \"h5py_record\", \"reward_log_file.json\")\n",
    "\n",
    "            if os.path.exists(recent_path):\n",
    "                most_recent = recent_path\n",
    "                break\n",
    "\n",
    "        # Retrieve the data for the task\n",
    "        if most_recent:\n",
    "            try:\n",
    "                with open(most_recent, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                    # Extract task-specific data and add to results\n",
    "                    if task_prefix in data:\n",
    "                        results[task_prefix] = {\"average_return\": data[task_prefix].get(\"average_return\", \"N/A\")}\n",
    "                    else:\n",
    "                        print(f\"Task '{task_prefix}' not found in JSON file: {most_recent}\")\n",
    "            except (json.JSONDecodeError, KeyError):\n",
    "                print(f\"Error reading JSON data from '{most_recent}'\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "tasks = [\n",
    "    \"Gendog266\", \"Gendog252\", \"Gendog72\", \"Gendog71\", \"Gendog207\",\n",
    "    \"Gendog104\", \"Gendog128\", \"Gendog272\", \"Gendog215\", \"Gendog248\",\n",
    "    \"Gendog229\", \"Gendog280\", \"Gendog278\", \"Gendog32\", \"Gendog55\",\n",
    "    \"Gendog75\", \"Gendog0\", \"Gendog282\", \"Gendog63\", \"Gendog47\",\n",
    "    \"Gendog241\", \"Gendog222\", \"Gendog286\", \"Gendog181\", \"Gendog183\",\n",
    "    \"Gendog97\", \"Gendog250\", \"Gendog20\", \"Gendog7\", \"Gendog258\",\n",
    "    \"Gendog111\", \"Gendog41\", \"Gendog132\", \"Gendog113\", \"Gendog31\",\n",
    "    \"Gendog290\", \"Gendog124\", \"Gendog46\", \"Gendog170\", \"Gendog48\",\n",
    "    \"Gendog204\", \"Gendog260\", \"Gendog298\", \"Gendog226\", \"Gendog261\",\n",
    "    \"Gendog37\", \"Gendog144\", \"Gendog244\"\n",
    "]\n",
    "\n",
    "base_path = \"/media/t7-ssd/Data/logs/rsl_rl\"\n",
    "\n",
    "expert_reward_results = get_rewards_as_dict(base_path, tasks)\n",
    "\n",
    "# # Print results\n",
    "# for task, average_return in expert_reward_results.items():\n",
    "#     print(f\"Task: {task}, Average Return: {average_return}\")\n"
   ],
   "id": "dbea22329888aeb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "expert_reward_results",
   "id": "ee654090eae86e74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_histograms_separately([expert_reward_results])",
   "id": "e2a215e80b543ca7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparative study",
   "id": "4760b32e01731e45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute expert_mean and expert_std\n",
    "expert_values = [v[\"average_return\"] for v in expert_reward_results.values()]\n",
    "expert_mean = np.mean(expert_values)\n",
    "expert_std = np.std(expert_values)\n",
    "\n",
    "# Calculate statistics for bar chart\n",
    "means = [np.mean([v[\"average_return\"] for v in d.values()]) for d in data_dicts]\n",
    "stds = [np.std([v[\"average_return\"] for v in d.values()]) for d in data_dicts]\n",
    "\n",
    "# Add expert values to bar chart\n",
    "x_labels = [f\"File {i+1}\" for i in range(len(data_dicts))] + [\"Expert\"]\n",
    "means.append(expert_mean)\n",
    "stds.append(expert_std)\n",
    "\n",
    "# Plot bar chart with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_labels, means, yerr=stds, capsize=5, alpha=0.7, color=['blue'] * len(data_dicts) + ['red'])\n",
    "plt.ylabel(\"Mean Average Return\")\n",
    "plt.title(\"Bar Chart with Error Bars (Including Expert)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot line plot with expert mean and std\n",
    "all_means = [np.mean([v[\"average_return\"] for v in d.values()]) for d in data_dicts]\n",
    "all_stds = [np.std([v[\"average_return\"] for v in d.values()]) for d in data_dicts]\n",
    "labels = [f\"File {i+1}\" for i in range(len(data_dicts))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(labels, all_means, yerr=all_stds, fmt='-o', capsize=5, color='green', alpha=0.7, label=\"Files\")\n",
    "plt.axhline(expert_mean, color='red', linestyle='--', label=\"Expert Mean\")\n",
    "plt.axhline(expert_mean + expert_std, color='red', linestyle=':', label=\"Expert Mean + Std\")\n",
    "plt.axhline(expert_mean - expert_std, color='red', linestyle=':', label=\"Expert Mean - Std\")\n",
    "plt.ylabel(\"Average Return\")\n",
    "plt.title(\"Line Plot Comparing All Files (Including Expert)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5c6b68bfec079e7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d3e7887e054b804"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de6b6aebd122a23b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b98e8ef8c406618"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bc2754dc9d9b550c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaac_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
