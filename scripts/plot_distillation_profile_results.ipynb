{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract scalar values from TensorBoard logs\n",
    "def extract_scalars_from_folder(folder, up_to_step=None):\n",
    "    scalar_data = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.startswith(\"events.out.tfevents\"):\n",
    "                log_path = os.path.join(root, file)\n",
    "\n",
    "                # Load TensorBoard logs\n",
    "                event_acc = EventAccumulator(log_path)\n",
    "                event_acc.Reload()\n",
    "\n",
    "                # Extract scalar values\n",
    "                for tag in event_acc.Tags().get(\"scalars\", []):\n",
    "                    if tag not in scalar_data:\n",
    "                        scalar_data[tag] = []\n",
    "\n",
    "                    for scalar_event in event_acc.Scalars(tag):\n",
    "                        if up_to_step is None or scalar_event.step <= up_to_step:\n",
    "                            scalar_data[tag].append(scalar_event.value)\n",
    "\n",
    "    # Compute mean for each scalar\n",
    "    mean_values = {tag: sum(values) / len(values) for tag, values in scalar_data.items() if values}\n",
    "    return mean_values\n",
    "\n",
    "# Function to process multiple folders\n",
    "def extract_scalars_from_folders(folders, up_to_step=None):\n",
    "    all_results = {}\n",
    "    for folder in folders:\n",
    "        print(f\"Processing folder: {folder}\")\n",
    "        all_results[folder] = extract_scalars_from_folder(folder, up_to_step)\n",
    "    return all_results\n",
    "\n",
    "# Function to format the scalar data into a structured table\n",
    "def print_structured_data(scalar_data):\n",
    "    all_dataframes = []\n",
    "    for folder, scalars in scalar_data.items():\n",
    "        df = pd.DataFrame.from_dict(scalars, orient=\"index\", columns=[\"Mean Value\"])\n",
    "        df.index.name = \"Scalar Name\"\n",
    "        df[\"Folder\"] = folder\n",
    "        all_dataframes.append(df)\n",
    "\n",
    "    result_df = pd.concat(all_dataframes)\n",
    "    print(result_df)\n",
    "\n",
    "# List of TensorBoard log folders\n",
    "folders = [\"/home/albert/github/embodiment-scaling-law-sim2real/log_dir/test_2\",\n",
    "           \"/home/albert/github/embodiment-scaling-law-sim2real/log_dir/test_3090_2\",\n",
    "           \"/home/albert/github/embodiment-scaling-law-sim2real/log_dir/test_4090_2\"]  # Replace with your actual log directories\n",
    "\n",
    "# Specify the timestep up to which you want to calculate the mean\n",
    "up_to_step = 70000  # Replace with your desired step limit\n",
    "\n",
    "# Extract and process the scalar data\n",
    "scalar_means = extract_scalars_from_folders(folders, up_to_step)\n",
    "\n",
    "# Print the results in a structured format\n",
    "print_structured_data(scalar_means)\n"
   ],
   "id": "cf6eb36f9154a22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scalar_means",
   "id": "b69c11f25740d646"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "663c2d1773148f5"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
